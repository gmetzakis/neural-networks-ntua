# -*- coding: utf-8 -*-
"""Neural_Networks_Ex1_039_Asimaki_Skoufis_Metzakis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UWzfvkVUTikRUm1obgFRJ_H2KZfL7hQ6

# Στοιχεία Ομάδας

Α/Α ομάδας: 39

Ασημάκη Γεωργία Γρηγορία -- 03116197

Μετζάκης Ιωάννης -- 03116202

Σκούφης Πέτρος -- 03116141

Μικρό Dataset (S12)
Μεγάλο Dataset (B06)
"""

## Μικρό dataset (S12)
## Μεγάλο dataset (B06)
## Α/Α ομάδας: 39
## Ασημάκη Γεωργία Γρηγορία -- 03116197
## Μετζάκης Ιωάννης -- 03116202
## Σκούφης Πέτρος -- 03116141

"""# S12"""

import pandas
import csv
import numpy as np
import sklearn
import seaborn as sns
import matplotlib as mat

lsvt = pandas.read_csv('LSVT_voice_rehabilitation.csv')
lsvt

print(lsvt.isnull().any().sum())

print(np.bincount(lsvt['Binary class 1=acceptable, 2=unacceptable']))

"""# LSVT_voice_rehabilitation dataset


* Το συγκεκριμένο dataset αξιολογεί εάν η θεραπεία αποκατάστασης φωνής οδηγεί σε αποδεκτά ή μη, φωνητικά αποτελέσματα (acceptable, unacceptable). Κάθε χαρακτηριστικό αντιστοιχεί στην εφαρμογή ενός αλγορίθμου επεξεργασίας σήματος ομιλίας που προσπαθεί να χαρακτηρίσει το σήμα. Οι αλγόριθμοι αυτοί περιλαμβάνουν τυπικές μεθόδους ανάλυσης διαταραχών, wavelet-based και frequency-based χαρακτηριστικά, καθώς επίσης και εργαλεία εξαγωγής μη γραμμικών σειρών.


* Το dataset αποτελείται από 128 δείγματα, και 310 ποσοτικά χαρακτηριστικά.

* Υπάρχουν επικεφαλίδες για κάθε κολόνα, δηλαδή για κάθε χαρακτηριστικό.

* Οι ετικέτες των κλάσεων είναι οι '1,2', ενώ βρίσκονται στην 1η κολόνα με επικεφαλίδα "Binary class 1=acceptable, 2=unacceptable".

* Στο xcel αρχείο που περιείχε το dataset χρειάστηκε να ενώσουμε το sheet των κλάσεων με αυτό των χαρακτηριστικών, και στη συνέχεια να το κάνουμε export to csv.

* Δεν υπάρχουν απουσιάζουσες τιμές στο dataset, αφού η ***'lsvt.isnull().any().sum())'*** επιστρέφει 0 (όπου "lvst" το dataset).

* Από την ***'np.bincount(lsvt['Binary class 1=acceptable, 2=unacceptable'])'*** βλέπουμε πως έχουμε 2 κλάσεις, όπου 42 δείγματα ανήκουν στην κλάση 1, ενώ 84 δείγματα ανήκουν στην κλάση 2. Συνεπώς το dataset είναι μη ισορροπημένο, αφού η κλάση 2 είναι 2 φορές πιο συχνή από την κλάση 1.
"""

features_names = (lsvt.columns[1:].to_list())
features = lsvt.iloc[:,1:].to_numpy()
label_names = ['acceptable','unacceptable']
labels = lsvt['Binary class 1=acceptable, 2=unacceptable']

"""Επεξεργαζόμαστε κατάλληλα τις γραμμές και στήλες του dataset, και στη συνέχεια το χωρίζουμε σε train και test set, με μέγεθος test set 20%.

Για την ταξινόμηση θα εξετάσουμε τους ταξινομητές **dummy, Gaussian Naive Bayes, kNN**, ενώ για την επιλογή του μοντέλου θα χρησιμοποιήσουμε τις μετρικές **f1_micro** και **f1_macro**.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=2)

"""Αρχικά θα εξετάσουμε τον **dummy** ταξινομητή.

Ο ταξινομητής dummy δεν επιδέχεται βελτίωσης, καθώς δεν μπορεί να αντλήσει πληροφορίες από τα χαρακτηριστικά του dataset. Παρ' όλα αυτά, δέχεται διάφορες τακτικές ταξινόμησης. Για αυτό το λόγο, θα κάνουμε cross validation για να βρούμε ποιά είναι η βέλτιστη για κάθε μετρική, και θα τη χρησιμοποιήσουμε για τους υπολογισμούς μας.
"""

from sklearn.dummy import DummyClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score

dc_uniform = DummyClassifier(strategy="uniform")
dc_constant_1 = DummyClassifier(strategy="constant", constant=1)
dc_constant_2 = DummyClassifier(strategy="constant", constant=2)
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")

tactics = [dc_uniform, dc_constant_1, dc_constant_2, dc_most_frequent, dc_stratified]
metrics = ['f1_micro', 'f1_macro']
average_f1 = ['micro','macro']
f1_score_dummy = []

for j in range(0,2):
    cv_score = []
    for i in tactics:
        score = cross_val_score(i,X_train,y_train,cv=10, scoring=metrics[j]).mean()
        cv_score.append(score)

    ideal = tactics[cv_score.index(max(cv_score))]


    ideal.fit(X_train,y_train)
    preds = ideal.predict(X_test)
    cnf_matrix = confusion_matrix(y_test, preds)
    f1_score_dummy.append(f1_score(y_test,preds,average=average_f1[j]))

    print("Βέλτιστη τεχνική με χρήση μετρικής '%s': " %metrics[j],ideal)
    print("\nΠίνακας Σύγχησης:", '\n',cnf_matrix)
    print("\n%s average: " %metrics[j], f1_score_dummy[j])
    print('\n',classification_report(y_test, preds, target_names=label_names))
    print('\n\n')

"""## Λίγα σχόλια

Για την πρώτη στρατηγική (constant 2) έχουμε μηδενικά precision και recall στην κλάση 1, πράγμα απόλυτως λογικό αφού ο ταξινομητής προβέπει αποκλεισιτκά από την κλάση 2. Επομένως, έτσι εξηγείται και το recall = 1 της κλάσης 2, αφού λόγω της πρόβλεψης αποκλειστικά από την κλάση 2, δεν υπάρχουν false negatives.

Παρατηρούμε γενικότερα πως, όπως αναμέναμε, ο dummy ταξινομητής έχει αρκετά χαμηλή απόδοση.

Στη συνέχεια εξετάζουμε τους ταξινομητές **Gaussian Naive Bayes** και **kNN**.

Αρχικά φορτώνουμε όλες τις απαραίτητες βιβλιοθήκες και ορίζουμε τους προς εξέταση μετασχηματιστές για την προεπεξεργασία (όπως δίνονται στα notebooks του εργαστηρίου).
"""

#from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
import time


# φέρνουμε τις γνωστές μας κλάσεις για preprocessing
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει .transform kai ΄όχι ως scale()
from sklearn.preprocessing import MinMaxScaler
from imblearn.over_sampling import RandomOverSampler
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV

# αρχικοποιούμε τον εκτιμητή (ταξινομητής) και τους μετασχηματιστές χωρίς υπερ-παραμέτρους
selector = VarianceThreshold()
#scaler = StandardScaler()
scaler = MinMaxScaler()
ros = RandomOverSampler()
pca = PCA()
gnb = GaussianNB()
clf = KNeighborsClassifier(n_jobs=-1)

"""Και για τους 2 ταξινομητές θα χρησιμοποίησουμε απαραίτητα τον RandomOverSampler, καθώς έχουμε μη ισορροπημένο dataset, ενώ δεν έχουμε αρκετά δείγματα ώστε να είναι δυνατή η αφαίρεση κάποιων δειγμάτων από την συχνότερη κλάση.

Επίσης, θα κάνουμε κανονικοποίηση των χαρακτηριστικών με χρήση του MinMaxScaler, καθώς βλέπουμε πολύ υψηλές τιμές στο variance, πράγμα που καθιστά δυσκολότερη την εκπαίδευση του εκτιμητή.                       
Συγκεκριμένα, η ***np.mean(X_train.var(axis=0))*** επιστρέφει 8.867086483933294e+17.

# Βελτιστοποίηση υπερπαραμέτρων

Για τους 2 εκτιμητές, υπολογίσαμε την επίδοσή τους πριν και μετά τη βελτιστοποίηση των παραμέτρων είτε των ταξινομητών (kNN), είτε των μετασχηματιστών (scaler, selector, pca). 

Για τη βελτιστοποίηση των παραπάνω παραμέτρων κάναμε χρήση της GridSearchCV, όπου ξεκινώντας από ένα ευρύ φάσμα τιμών για κάθε υπερπαράμετρο, εστιάζαμε επαναληπτικά στο βέλτιστο κάθε φορά υποσύνολο, περιορίζοντας έτσι την αναζήτηση, έως ότου δε βλέπαμε καμία βελτίωση. 

Για την εύρεση των βέλτιστων υπερπαραμέτρων και του ιδανικού συνδιασμού μετασχηματιστών μέσω της GridSearchCV, χρησιμοποιήσαμε 10-fold cross-validation.

Οι αρχικές τιμές που δοκιμάσαμε ήταν οι εξής:

* vthreshold = [0.01, 0.02, 0.03, 0.04, 0.05]
* n_components = [10, 20, 30, 40, 50, 60]
* k = [1, 6, 11, 21, 31, 41]

To block κώδικα που τρέχαμε επαναληπτικά είναι το παρακάτω:
"""

'''
vthreshold = [0.01, 0.02, 0.03, 0.04, 0.05]
n_components = [10, 20, 30, 40, 50, 60]
k = [1, 6, 11, 21, 31, 41]

estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components = n_components, kNN__n_neighbors=k), cv=10, scoring='f1_micro', n_jobs=-1)


import time
start_time = time.time()
estimator.fit(X_train, y_train)
preds = estimator.predict(X_test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(y_test, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)
''';

"""Όπου ανάλογα με τη μετρική απόδοσης που χρησιμοποιούσαμε, όριζαμε αντίστοιχα την παράμετρο "scoring" της GridSearchCV.

Έπειτα, προσαρμόζαμε το διάστημα αναζήτησης στις τιμές που επέστρεφε η ***estimator.best_params_*** και επαναλαμβάναμε.

Παρακάτω παρουσιάζονται οι τελικές βέλτιστες τιμές των υπερπαραμέτρων αυτών για κάθε εκτιμητή όπως αυτές προέκυψαν πειραματικά, οι επιδόσεις τους πριν και μετά τη βελτιστοποίηση τους, καθώς και οι χρόνοι εκτέλεσης του τελικού fit και predict.                

Βέβαια, ο χρόνος εκτέλεσης αυξάνεται όσο αυξάνονται οι τιμές των υπερπαραμέτρων προς εξέταση, κάτι που δε θα φανεί παρακάτω καθώς παρουσιάζουμε μόνο την τελευταία  χρονικά αναζήτηση, όπου έχουμε ήδη περιορίσει το πεδίο τιμών των υπερπαραμέτρων.


# Gaussian Naive Bayes
"""

pipe = Pipeline(steps=[('scaler', scaler), ('selector', selector), ('sampler', ros), ('gnb', gnb)])

print('\033[1m' + "Πριν τη βελτιστοποίηση υπερπαραμέτρων: " + '\033[0m', '\n')
pipe.fit(X_train,y_train)
preds = pipe.predict(X_test)
acc_gnb_before = accuracy_score(y_test,preds)
conf_gnb_before = confusion_matrix(y_test, preds)
print(classification_report(y_test, preds))
print("Πίνακας Σύγχησης:", '\n',conf_gnb_before)



print('\n\n\n','\033[1m' + "Μετά τη βελτιστοποίηση υπερπαραμέτρων με χρήση της 'f1_micro': " + '\033[0m','\n')
vthreshold = [0.042]
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold), cv=10, scoring='f1_micro', n_jobs=-1)

start_time = time.time()
estimator.fit(X_train, y_train)
preds = estimator.predict(X_test)
conf_gnb_f1_micro = confusion_matrix(y_test, preds)
acc_gnb_f1_micro = accuracy_score(y_test,preds)
gnb_f1_micro_score = f1_score(y_test, preds, average='micro')
time_gnb_f1_micro = (time.time() - start_time)
print("Συνολικός χρόνος fit και predict: %s seconds" % time_gnb_f1_micro)
print(classification_report(y_test, preds))
print("Πίνακας Σύγχησης:", '\n',conf_gnb_f1_micro)
print("\nf1-micro average: ", gnb_f1_micro_score)
print('\n',estimator.best_estimator_)
print(estimator.best_params_)



print('\n\n\n','\033[1m' + "Μετά τη βελτιστοποίηση υπερπαραμέτρων με χρήση της 'f1_macro': " + '\033[0m','\n')
vthreshold = [0.04]
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold), cv=10, scoring='f1_macro', n_jobs=-1)

start_time = time.time()
estimator.fit(X_train, y_train)
preds = estimator.predict(X_test)
conf_gnb_f1_macro = confusion_matrix(y_test, preds)
acc_gnb_f1_macro = accuracy_score(y_test,preds)
gnb_f1_macro_score = f1_score(y_test, preds, average='macro')
time_gnb_f1_macro = (time.time() - start_time)
print("Συνολικός χρόνος fit και predict: %s seconds" % time_gnb_f1_macro)
print(classification_report(y_test, preds))
print("Πίνακας Σύγχησης:", '\n',conf_gnb_f1_macro)
print("\nf1-macro average: ", gnb_f1_macro_score)
print('\n', estimator.best_estimator_)
print(estimator.best_params_)

"""## Λίγα σχόλια

Παρατηρούμε πως υπάρχει μεγάλη αύξηση στην επίδοση του ταξινομητή μετά τη βελτιστοποίηση των υπερπαραμέτρων, γεγονός που οφείλεται στη σημαντική μείωση των false positive για την κλάση 1, άρα ταυτόχρονα μείωση των false negative για την κλάση 2. Αυτό αποτυπώνεται και στις τιμές των precision και recall για τις κλάσεις 1 και 2 αντίστοιχα, όπου παρουσιάζουν σημαντική αύξηση.

# kNN
"""

pipe = Pipeline(steps=[('scaler', scaler), ('selector', selector), ('sampler', ros), ('pca', pca), ('kNN', clf)])

print('\033[1m' + "Πριν τη βελτιστοποίηση υπερπαραμέτρων: " + '\033[0m', '\n')
pipe.fit(X_train,y_train)
preds = pipe.predict(X_test)
conf_kNN_before = confusion_matrix(y_test, preds)
acc_kNN_before = accuracy_score(y_test,preds)
print(classification_report(y_test, preds))
print("Πίνακας Σύγχησης:", '\n',conf_kNN_before)



print('\n\n\n','\033[1m' + "Μετά τη βελτιστοποίηση υπερπαραμέτρων με χρήση της 'f1_micro': " + '\033[0m','\n')
vthreshold = [0.019]
n_components = [20]
k = [1]
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components, kNN__n_neighbors=k), cv=10, scoring='f1_micro', n_jobs=-1)

start_time = time.time()
estimator.fit(X_train, y_train)
preds = estimator.predict(X_test)
conf_kNN_f1_micro = confusion_matrix(y_test, preds)
acc_kNN_f1_micro = accuracy_score(y_test,preds)
kNN_f1_micro_score = f1_score(y_test, preds, average='micro')
time_kNN_f1_micro = (time.time() - start_time)
print("Συνολικός χρόνος fit και predict: %s seconds" % time_kNN_f1_micro)
print(classification_report(y_test, preds))
print("Πίνακας Σύγχησης:", '\n',conf_kNN_f1_micro)
print("\nf1-micro average: ", kNN_f1_micro_score)
print('\n',estimator.best_estimator_)
print(estimator.best_params_)



print('\n\n\n','\033[1m' + "Μετά τη βελτιστοποίηση υπερπαραμέτρων με χρήση της 'f1_macro': " + '\033[0m','\n')
vthreshold = [0.022]
n_components = [38]
k = [1]
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components, kNN__n_neighbors=k), cv=10, scoring='f1_macro', n_jobs=-1)

start_time = time.time()
estimator.fit(X_train, y_train)
preds = estimator.predict(X_test)
conf_kNN_f1_macro = confusion_matrix(y_test, preds)
acc_kNN_f1_macro = accuracy_score(y_test,preds)
kNN_f1_macro_score = f1_score(y_test, preds, average='macro')
time_kNN_f1_macro = (time.time() - start_time)
print("Συνολικός χρόνος fit και predict: %s seconds" % time_kNN_f1_macro)
print(classification_report(y_test, preds))
print("Πίνακας Σύγχησης:", '\n',conf_kNN_f1_macro)
print("\nf1-macro average: ", kNN_f1_macro_score)
print('\n',estimator.best_estimator_)
print(estimator.best_params_)

"""## Λίγα σχόλια

Όπως και στον gnb ταξινομητή, η βελτίωση που παρατηρούμε οφείλεται στην αύξηση των σωστών προβλέψεων για την κλάση 2, αφού η κλάση 1 δεν είχε εξαρχής false negative. 

Επίσης, είναι σημαντικό να αναφέρουμε πως η GridSearchCV επέστρεψε ως βέλτιστη υπερπαράμετρο για n_neighbors την τιμή 1. Αυτό μπορεί να έχει ως αποτέλεσμα ένα πιθανό overfitting, καθώς για το συγκεκριμένο train-test μπορεί να έχουμε υψηλή επίδοση, ωστόσο για διαφορετικό train-test split, είναι πιθανό να προκύψουν διαφορετικά αποτελέσματα.

# Συγκεντρωμένα αποτελέσματα
"""

print('\033[1m' + "Χρόνοι εκτέλεσης: " + '\033[0m', '\n')
print("gnb:")
print("     'f1_micro': ", time_gnb_f1_micro, "sec")
print("     'f1_macro': ", time_gnb_f1_macro, 'sec\n')

print("kNN:")
print("     'f1_micro': ", time_kNN_f1_micro, "sec")
print("     'f1_macro': ", time_kNN_f1_macro, 'sec\n\n\n')




print('\033[1m' + "Μεταβολή επίδοσης: " + '\033[0m','\n')
print("gnb:")
print("     Accuracy πριν τη βελτιστοποίηση: ", round(acc_gnb_before*100,1),"%")
print("     Accuracy μετά τη βελτιστοποίηση με 'f1_micro': ", round(acc_gnb_f1_micro*100,1),"%")
print("     Accuracy μετά τη βελτιστοποίηση με 'f1_macro': ", round(acc_gnb_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((acc_gnb_f1_micro-acc_gnb_before)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((acc_gnb_f1_macro-acc_gnb_before)*100,1),"%\n")


print("kNN:")
print("     Accuracy πριν τη βελτιστοποίηση: ", round(acc_kNN_before*100,1),"%")
print("     Accuracy μετά τη βελτιστοποίηση με 'f1_micro': ", round(acc_kNN_f1_micro*100,1),"%")
print("     Accuracy μετά τη βελτιστοποίηση με 'f1_macro': ", round(acc_kNN_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((acc_kNN_f1_micro-acc_kNN_before)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((acc_kNN_f1_macro-acc_kNN_before)*100,1),"%\n\n\n")




print('\033[1m' + "Σύγκριση ταξινομητών ανά μετρική: " + '\033[0m','\n')
data = {'dummy': [f1_score_dummy[0], f1_score_dummy[1]],
        'gnb': [gnb_f1_micro_score, gnb_f1_macro_score],
        'kNN': [kNN_f1_micro_score, kNN_f1_macro_score],
        'metric': ['f1_micro','f1_macro']}
dataframe = pandas.DataFrame(data, columns = ['dummy','gnb','kNN','metric'])
df = pandas.melt(dataframe, id_vars="metric", var_name="Classifier", value_name="score")
sns.barplot(x='metric', y='score', hue='Classifier', data=df);

"""## Λίγα σχόλια

* Σχετικά με τους χρόνους εκτέλεσης fit και predict, παρατηρούμε πως ο ταξινομητής kNN χρειάζεται υπερδιπλάσιο χρόνο, γεγονός που οφείλεται στον μεγαλύτερο αριθμό υπερπαραμέτρων προς βελτιστοποίηση.

* Σχετικά με τη βελτίωση της επίδοσης των 2 ταξινομητών, βλέπουμε πως ο gnb παρουσιάζει μεγαλύτερη σε σχέση με τον kNN, κυρίως λόγω της αρκετά χαμηλής του απόδοσης πριν τη βελτιστοποίση του, αφού οι τελικές τους επιδόσεις δεν διαφέρουν σημαντικά.

* Τέλος, σχετικά με τη σύγκριση των μετρικών f1_micro και f1_macro, μπορούμε να πούμε πως σε γενικές γραμμές παρουσιάζουν αντίστοιχη αύξηση για κάθε ταξινομητή, με την f1_micro ωστόσο να πετυχαίνει υψηλότερα αποτελέσματα σε κάθε περίπτωση.

#B06

# Imports and Drive setup
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd 
import random 
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score
from sklearn.model_selection import cross_val_score, learning_curve, cross_validate, GridSearchCV
from sklearn.pipeline import Pipeline
import matplotlib.cm as cm
from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει .transform kai ΄όχι ως scale()
from sklearn.decomposition import PCA
# use seaborn plotting defaults
import seaborn as sns; sns.set()
import time

# Do not execute if you are not using Drive
from google.colab import drive
drive.mount('/content/drive')

#%cd "drive/My Drive/Neural_Networks/Lab1"

#!ls

"""# Data imports and basic preprocessing

### Λίγα πράγματα για το dataset

Το dataset που καλούμαστε να εξετάσουμε σε αυτό το notebook είναι το Semeion Handwritten Digit Data Dataset, το οποίο περιλαμβάνει 1593 δείγματα σκαναρισμένων εικόνων που απεικονίζουν ψηφία (0-9) γραμμένα στο χέρι από 80 περίπου διαφορετικούς ανθρώπους.

Το κάθε χειρόγραφο δείγμα σαρώθηκε σε ένα κουτί 16X16 pixels σε κλίμακα του γκρι με 256 τιμές. Έπειτα με κατωφλιοποίηση ανατέθηκε σε κάθε pixel τιμή 0|1 ανάλογα με την ένταση που είχε το γκρι στο συγκεκριμένο pixel.
"""

# Φορτώνουμε το dataset το οποίο βρίσκεται στον τρέχοντα φάκελο
# Τα data δεν έχουν header
data = pd.read_csv('semeion.data', sep=' ',header=None)

data

"""Φορτώνοντας το dataset και κάνοντας ένα preview παρατηρούμε τα εξής:

* Υπάρχουν συνολικά 1593 δείγματα καθένα από τα οποία αντιστοιχεί και σε μία σειρά (row) του Dataframe
* Κάθε δείγμα έχει 256 χαρακτηριστικά, το καθένα από τα οποία αντιστοιχεί και σε ένα pixel της σκαναρισμένης εικόνας. Τα pixel βρίσκονται στις πρώτες 256 στήλες του Dataframe. Οι τιμές τους έχουν προκύψει από κατωφλιοποίηση και για αυτό είναι binary (0|1).
* Δεν υπάρχουν επικεφαλίδες στα δεδομένα ούτε αρίθμηση.
* Το dataset ειναι multiclass και οι ετικέτες των κλασεων εισάγονται ως 10 binary χαρακτηριστικά, καθένα από τα οποία αντιστοιχεί και σε μία κλάση-ψηφίο. Η ύπαρξη της τιμής 1 στο χαρακτηριστικό, υποδεικνύει πως το δείγμα ανήκει στη συγκεκριμένη κλάση. Κάθε δείγμα ανήκει σε μόνο μία κλάση.
* Δεν υπάρχουν απουσιάζουσες τιμές με εξαίρεση μία ολόκληρη κολώνα (την τελευταία), η οποία περιέχει μόνο **NaN** και την αγνοήσαμε

"""

# Φορτώνουμε τα 256 πρώτα χαρακτηριστικά στη μεταβλητή X_train και τις επιθυμητές εξόδους - ετικέτες στην y_train
X_train, y_train = data.iloc[:, :256].values, data.iloc[:, 256:266].values   #save train_data into numpy.ndarray type
print('X_train shape: {} /// y_train shape: {}'.format(X_train.shape, y_train.shape))
print('')

"""Τα δεδομένα μας είναι χωρισμένα σε κλάσεις με περίπου ίσο αριθμό δειγμάτων η καθεμία. Έχουμε δηλαδή ένα balanced dataset όπως φαίνεται και παρακάτω.


"""

print(np.sum(y_train, axis=0))

"""Παρακάτω κατασκευάζουμε μια απλή συνάρτηση, η οποία δέχεται ως όρισμα τον πίνακα με τις τιμές των χαρακτηριστικών και το index ενός συγκεκριμένου στοιχείου-εικόνας και μετατρέποντας το vector με τις τιμές των 256 pixels σε έναν πίνακα 16 X 16 το plotάρει δίνοντάς μας και οπτικό αποτέλεσμα. 

Το βήμα αυτό απλά μας βοηθά να επιβεβαιώσουμε πως κατανoήσαμε σωστά το dataset.
"""

def show_sample(X, index):
  plt.imshow((np.reshape((X[index,:]), (16,16))))   #reshape the 256 feautures of the specified index into an (16,16) array 
 
#lib.show_sample(X_train,130)
show_sample(X_train,587)
print(y_train[587]) #verification

"""Παρακάτω φαίνεται πως οι 10 κλάσεις που αντιστοιχούν στα 10 ψηφία εμφανίζονται σχεδόν με την ίδια συχνότητα στο dataset, δηλαδή περίπου 10%."""

np.sum(y_train, axis=0)/np.sum(y_train)

"""Παρακάτω πρόκειται να εκτελέσουμε το διαχωρισμό των δεδομένων σε train και test sets, κρατώντας ένα ποσοστό 30% των συνολικών δεδομένων ως test set. Θα χρησιμοποιήσουμε μία random state, ώστε να μπορούμε να αναπαράγουμε τον "τυχαίο" καθορισμό του train και test set σε περίπτωση που το χρειαστούμε."""

from sklearn.model_selection import train_test_split
# Split our data
train, test, train_labels, test_labels = train_test_split(X_train, y_train, test_size=0.3, random_state = 451)

"""Ελέγχουμε πως και το train set που δημιουργήσαμε έχει μια σχετική ισορροπία μεταξύ των κλάσεων, ώστε να υπάρχουν αρκετά δεδομένα για την εκπαίδευση των ταξινομητών για όλες τις κλάσεις."""

print(np.sum(train_labels, axis=0)/np.sum(train_labels))

"""Παρατηρήσαμε προηγουμένως πως οι ετικέτες του dataset δίνονταν σε μορφή binary labels, αλλά για να είναι πιο εύκολη η διαχείρισή τους θα της ενώσουμε σε ένα label το οποίο λαμβάνει τιμές από 0 έως 9, καθεμία από τις οποίες αντιστοιχεί και στην κάση του συγκεκριμένου ψηφίου.

Για να το κάνουμε αυτό θα χρησιμοποιήσουμε γινόμενο πινάκων πολλαπλασιάζοντας τον πίνακα των κλάσεων με τον πίνακα [0 1 2 3 4 5 6 7 8 9] των ετικετών.

Εναλλακτικά μπορούμε να χρησιμοποιήσουμε transformers αλλά είχαμε γράψει μεγάλο μέρος του Notebook όταν το καταλάβαμε και επιλέξαμε να μην το αλλάξουμε.
"""

classes = range(0,10)
unbin_train_labels = train_labels.dot(classes)
unbin_test_labels = test_labels.dot(classes)

"""# Data pre-processing

Στο σημείο αυτό θα ελέγξουμε τα χαρακτηριστικά του dataset ώστε να δούμε ποια είδη προεπεξεργασίας θα μπορούσαν να φανούν χρήσιμα.
"""

from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import PCA

var = np.var(train, axis=0)

print(var)

"""Παρατηρούμε πως αν και τα χαρακτηριστικά παίρνουν τιμές 0 ή 1 οι διασπορές τους κυμαίνονται μεταξύ του μηδενός και της μονάδας. Υποψιαζόμαστε, λοιπόν, πως θα αποδώσει η προεπεξεργασία με StandardScaler. 

Επίσης έχουμε πολλά χαρακτηριστικά καθένα από τα οποία έχει ένα μικρό κομμάτι μόνο της συνολικής πληροφορίας. Θα χρησιμποιήσουμε PCA, ώστε να μειώσουμε τις διαστάσεις και να αυξήσουμε την πληροφορία που περιέχει καθεμία από αυτές. Θα μπορούσαμε εναλλακτικά να ομαδοποιήσουμε τα pixels σε blocks, τεχνική που συναντάται συχνά στην επεξεργασία εικόνας, αλλά δε θα το κάνουμε καθώς ξεφεύγει από τα όρια και την ουσία της εργασίας.

# Dummy Classifier
"""

from sklearn.dummy import DummyClassifier

dc_uniform = DummyClassifier(strategy="uniform")
dc_constant_1 = DummyClassifier(strategy="constant", constant=1)
dc_constant_5 = DummyClassifier(strategy="constant", constant=5)
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")

#με τη μέθοδο fit "εκπαιδεύουμε" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)
model = dc_uniform.fit(train, unbin_train_labels)

#με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)
preds = dc_uniform.predict(test)

dummy_accuracy = dc_uniform.score(test, unbin_test_labels)

print(dummy_accuracy)

model = dc_constant_1.fit(train, unbin_train_labels)
preds = dc_constant_1.predict(test)
dummy_accuracy = dc_constant_1.score(test, unbin_test_labels) 
print(dummy_accuracy)

model = dc_most_frequent.fit(train, unbin_train_labels)
preds = dc_most_frequent.predict(test)
dummy_accuracy = dc_most_frequent.score(test, unbin_test_labels) 
print(dummy_accuracy)

dc_stratified = DummyClassifier(strategy="stratified")
model = dc_stratified.fit(train, unbin_train_labels)
preds = dc_stratified.predict(test)
dummy_accuracy = dc_stratified.score(test, unbin_test_labels) 
print(dummy_accuracy)

"""Σε γενικές γραμμές παρατηρούμε πως οι Dummy Classifiers δεν έχουν καμία δυνατότητα να εξάγουν πληροφορία από τα χαρακτηριστικά του dataset με αποτέλεσμα να μην έχουν καμία τύχη σε balanced multi-class datasets, όπως το dataset που εξετάζουμε αυτή τη στιγμή. Δεν θα αναλωθούμε σε περισσότερη αναζήτηση για «καλούς» Dummy ταξινομητές και θα περάσουμε αμέσως σε ταξινομητές οι οποίοι μπορούν να μας δώσουν ενδιαφέροντα αποτελέσματα.

# Gaussian Naive Bayes

## Ορισμός απλόυ GNB ως benchmark

Αρχικά θα δοκιμάσουμε τον default ταξινομητή Gaussian Naive Bayes χωρίς να κάνουμε κάποιο pre-processing στα δεδομένα μας, και θα χρησιμοποιήσουμε τα αποτελέσματα ως benchmark για τα αποτελέσματα της παραμετροποίησης.
"""

from sklearn.naive_bayes import GaussianNB
gnb_clf = GaussianNB()

gnb_clf.fit(train,unbin_train_labels)

gnb_preds = gnb_clf.predict(test)

gnb_accuracy = gnb_clf.score(test, unbin_test_labels)

print(gnb_accuracy)

"""## Εύρεση βέλτιστων υπερπαραμέτρων με GridSearch

Στο σημείο αυτό θα εισάγουμε pre-processing στα δεδομένα, προχωρόντας σε μείωση της διαστατικότητας του dataset χρησιμοποιώντας τον αλγόριθμο PCA για εξαγωγωγή των κύριων συνιστωσών. Θα χρησιμοποιήσουμε τη GridSearch, με σκοπό να ελέγξουμε την απόδοση του ταξινομητή Gaussian Naive Bayes ως προς f1-micro και f1-macro για διάφορους συνδυασμούς κύριων συνιστωσών στην PCA.
"""

gnb_gs = GaussianNB()

pca = PCA()
pipe = Pipeline(steps=[ ('pca', pca), ('GNB', gnb_gs)], memory = 'tmp')

n_components = [10, 25, 50, 90, 140, 200]
#n_components = [40,45,50,55,60]
#n_components = range(46,54)

estimator = GridSearchCV(pipe, dict(pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)

start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

estimator = GridSearchCV(pipe, dict(pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)

start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

"""Αφού βρήκαμε τον αριθμό κύριων συνιστωσών [n_components] της PCA, κοντά στον οποίο βρίσκεται η βέλτιστη λύση ως προς τις δύο μετρικές θα προσπαθήσουμε να επαναλάβουμε τη GridSearch μειώνοντας σε έκταση το διάστημα αναζήτησης των βέλτιστων παραμέτρων του pre-processing με σκοπό αυτή τη φορά να προσδιορίσουμε με ακόμα μεγαλύτερη ακρίβεια τις παραμέτρους του βέλτιστου ταξινομητή."""

n_components = [70, 80, 90, 100 , 110]
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [70, 80, 90, 100 , 110]
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [110,120,130,140]
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Έχοντας βρει τις βέλτιστες παραμέτρους για τη συγκεκριμένη προεπεξεργασία θα δοκιμάσουμε να εισάγουμε άλλα δύο στάδια προεπεξεργασίας προεπεξεργασίας. Συγκεκριμένα εισάγουμε έναν Selector με Variance Threshold με σκοπό να μη λάβουμε υπόψιν μας χαρακτριστικά με χαμηλή τιμή διασποράς και έπειτα έναν Standard Scaler. 

Αρχικά θεωρήσαμε πως τα δεδομένα μας ήταν σε αρκετά καλή μορφή ως προς του δύο παράγοντες και πως δε θα πετυχαίναμε μεγάλη διαφορά αλλά όπως φαίνεται παρακάτω τα νέα επίπεδα προεπεξεργασίας, βελτιώνουν έστυω και οριακά την επίδοση του ταξινομητή.


"""

selector = VarianceThreshold()
scaler = StandardScaler()
pipe2 = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('GNB', gnb_gs)], memory = 'tmp')
n_components = [10, 25, 50, 90, 140, 200]
estimator = GridSearchCV(pipe2, dict(pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

estimator = GridSearchCV(pipe2, dict(pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Παρατηρούμε επίσης πως η βέλτιστη παράμετρος για την PCA άλλαξε οπότε θα επανλάβουμε την αναζήτηση κοντά σε αυτό το διάστημα."""

selector = VarianceThreshold()
scaler = StandardScaler()
pipe2 = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('GNB', gnb_gs)], memory = 'tmp')
n_components = [40, 45, 50, 55, 60, 65, 70, 75, 80]
estimator = GridSearchCV(pipe2, dict(pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

estimator = GridSearchCV(pipe2, dict(pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""## Γενικά συμπεράσματα για την GridSearch στον GNB

Παρατηρούμε πως η εισαγωγή προεπεξεργασίας και η μείωση της διαστατικότητας αποδίδει πολύ καλά στον GNB βελτιώνοντας αισθητά την απόδοση. Κάνοντας χρήση της GridSearch και περιρίζοντας σταδιακά το διάστημα στο οποίο κινείται, η μόνη ελέυθερη παράμεάτρος του συστήματος προεπεξεργασίας-ταξινομητή, ο αριθμός των συνιστωσών της PCA καταφέρνουμε να προσεγγίσουμε σε ικανοποιητικό βαθμό το συνδυασμό υπερπαραμέτρων στον οποίο θεωρούμε πως συναντάται η μέγιστη απόδοση ως προς f1-macro και f1-micro.

Ενδιαφέρον λεπττέροεμια αποτελεί το γεγονός πως η βέλτιστη τιμή των **n_components** της PCA είναι και για την f1-micro και για την f1-macro ίση με 70.

# KNN

Σε αυτή την ενότητα θα προσπαθήσουμε να κατασκευάσουμε το βέλτιστο KNN ταξινομητή, χρησιμοποιώντας την GridSearch με σκοπό να προσδιορίσουμε πάλι όπως νωρίτερα το βέλτιστο συνδυασμό παραμέτρων ταξινομητή και προεπεξεργασίας.

## Ορισμός απλού KNN ως benchmark

Αρχικά εκπαιδεύουμε έναν ταξινομητή KNN στα δεδομένα, χωρίς καμία προεπεξεργασία και χωρίς να πειράξουμε τις υπερπαραμέτρους με σκοπό να χρησιμοποιηθεί πάλι ως benchmark.
"""

from sklearn.neighbors import KNeighborsClassifier

knn_clf = KNeighborsClassifier().fit(train, unbin_train_labels)

knn_accuracy = knn_clf.score(test, unbin_test_labels) 
print(knn_accuracy)

print(classification_report(unbin_test_labels, knn_preds))

"""Παρατηρούμε πως ακόμα και χωρίς καμία παραμετροποίηση, ο KNN καταφέρνει να προβλέψει σωστά με ακρίβεια 90%, πράγμα το οποίο αποτελεί βελτίωση συγκρτικά με την προηγούμενη μέθοδο. Το μόνο που μένει τώρα είναι να δούμε πόσο μπορούμε να βελτιώσουμε αυτό το score προσθέτοντας προεπεξεργασία και μεταβάλλοντας τις υπερπαραμέτρους του ταξινομητή.

## Εύρεση βέλτιστων υπερπαραμέτρων με GridSearch

Και σε αυτό το παράδειγμα θα πειραματιστούμε με διάφορα επίπεδα προεπεξεργασίας (Selector-Scaler-PCA) καθώς και με τις παρακάτω παραμέτρους του KNN:
* distance
* weights
* number of neighbors 
* n_components (PCA)
"""

knn_gs = KNeighborsClassifier(n_jobs=-1)

pipe = Pipeline(steps=[('pca', pca), ('kNN', knn_gs)])

n_components = [10, 25, 50, 90, 140, 200]
distance = ['euclidean', 'manhattan', 'chebysev','minkowski']
w = ['uniform','distance']
k = [1, 6, 11, 21, 31, 41] # η υπερπαράμετρος του ταξινομητή

estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_macro', n_jobs=-1)

start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [35, 45, 50, 55, 65, 140, 200]
distance = ['euclidean', 'manhattan', 'chebysev','minkowski']
w = ['uniform','distance']
k = [1, 2 , 3, 4, 5] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(30,40,2)
distance = ['euclidean']
w = ['distance']
k = [ 4] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Παρατηρούμε, λοιπόν πως για τον KNN ως προς το f1-macro οι βέλτιστες παράμετροι είναι για το pre-processing, όταν αυτό αποτελείται μόνο από PCA είναι η χρήση 34 συνιστωσών. Επίσης για τις υπερπαραμέτρους του ταξινομητή βέλτιστη μετρική για υπολογισμό είναι η Εκλείδεια απόσταση, με αριθμό γειτόνων 4 και βάρη ως συνάρτηση της απόστασης."""

n_components = [10, 25, 50, 90, 140, 200]
distance = ['euclidean', 'manhattan', 'chebysev','minkowski']
w = ['uniform','distance']
k = [1, 6, 11, 21, 31, 41] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(20,36,2)
distance = ['euclidean']
w = ['distance']
k = range(3,9) # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Στη συγκεκριμένη περίπτωση μάλιστα παρατηρούμε πως και ως προς f1-micro έχουμε τις ίδες βέλτιστες υπερπαραμέτρους."""

knn_gs = KNeighborsClassifier(n_jobs=-1)
pipe = Pipeline(steps=[ ('pca', pca), ('kNN', knn_gs)])
n_components = [30, 40, 50, 60, 70]
distance = ['euclidean', 'manhattan', 'chebysev']
w = ['uniform','distance']
k = [4,5,6,7,8,9] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

"""Σε αυτό το σημείο, όπως και πριν θα προχωρήσουμε στην προσθήκη δύο ακόμα σταδίων στο pre-processing, ενός Selector και ενός Scaler και θα επαναλάβουμε την παραπάνω διαδικασία."""

selector = VarianceThreshold()
scaler = StandardScaler()
knn_gs = KNeighborsClassifier(n_jobs=-1)
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('kNN', knn_gs)])
n_components = [10, 25, 50, 90, 140, 200]
distance = ['euclidean', 'manhattan', 'chebysev','minkowski']
w = ['uniform','distance']
k = [4,5,6,7,8,9] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(20,40,4)
distance = ['euclidean']
w = ['distance']
k = [3,4,5] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

"""Και αντίστοιχα για f1-micro:"""

n_components = [10, 25, 50, 90, 140, 200]
distance = ['euclidean', 'manhattan', 'chebysev','minkowski']
w = ['uniform','distance']
k = [4,5,6,7,8,9] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(20,40,2)
distance = ['euclidean']
w = ['distance']
k = [4,5,6,7] # η υπερπαράμετρος του ταξινομητή
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, kNN__n_neighbors=k, kNN__metric=distance, kNN__weights = w), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""## Γενικά συμπεράσματα για την GridSearch στον ΚΝΝ

Παρατηρούμε πως παρά τη μεγάλη αρχική ακρίβεια και καλή απόδοση του KNN υπάρχει δυνατότητα για βελτίωση με την κατάλληλη προεπεξεργασία. Η διαδικασία που ακολουθήσαμε και αυτή τη φορά, λόγω του υποφερτού ως προς το χρόνο κόστους του KNN και τον περιορισμένο αριθμό παραμέτρων που μπορούσαμε να βελτιστοποιήσουμε ήταν σταδιακή μείωση των διαστημάτων αναζήτησης, κρατώντας και εμβαθύνοντας σταδιακά στις παραμέτρους και τους συνδυασμούς που έδιναν τα καλύτερα αποτελέσματα.

Συγκεκριμένα, αρχικά "κλειδώσαμε" την μετρική απόστασης σε "euclidean" και τα βάρη με βάση την απόσταση "distance". Έπειτα με αυτά ως σταθερά κάναμε σχεδόν εξαντλητική αναζήτηση για τις βέλτιστες τιμές των υπερπαραμέτρων "n_components" της PCA και n_neoghbors του KNN.

Σημειώνεται εδώ πως η εξαντλητική αναζήτηση ως προς όλες τις παραμέτρους ήταν εφικτή στη συγκεκριμένη περίπτωση αλλά επιλέξαμε να μην την υλοποιήσουμε, καθώς θεωρήσαμε πως το πνεύμα της εργασίας είναι κυρίως να εξετάσουμε οι ίδιοι τα αποτελέσματα και να προσεγγίσουμε σταδιακά τη λύση ακόμα και αν δεν έχουμε τους πόρους για να προβούμε σε εξαντλητική αναζήτηση.

# MLP

Στην ενότητα αυτή θα υλοποιήσουμε έναν Multi Layer Perceptron ταξινομητή, με ένα μόνο επίπεδο κρυμμένων νευρώνων, ώστε να εκτελέσει την κατηγοριοποίηση των εικόνων των ψηφίων.

## Ορισμός απλού MLP ως benchmark

Σε αυτό το σημείο θα υλοποιήσουμε τον απλούστερο δυνατό MLP ταξινομητή, χωρίς καμία προ-επεξεργασία ή παραμετροποίηση, ώστε να τον χρησιμοποιήσουμε ως benchmark για τις μελλοντικές βελτιώσεις μας.
"""

from sklearn.neural_network import MLPClassifier

mlp_clf = MLPClassifier()
mlp_clf.fit(train, unbin_train_labels)

mlp_acc = mlp_clf.score(test, unbin_test_labels)

print(mlp_acc)

"""## Εύρεση βέλτιστων υπερπαραμέτρων με GridSearch

Στο σημείο αυτό θα προσπαθήσουμε να βελτιώσουμε την απόδοση του MLP ταξινομητή μας προσθέτοντας προεπεξεργασία και αλλάζοντας τις τιμές των υπερπαραμέτρων του. Οι παράμετροι που θα «πειράξουμε» είναι οι:

•	hidden_layer 

•	activation 

•	solver 

•	learning_rate 

•	max_iter : 

•	alpha 

•	n_components  (PCA)

Παρατηρούμε, λοιπόν σχεδόν άμεσα πως υπάρχουν πάρα πολλοί πιθανοί συνδυασμοί αυτών των παραμέτρων, τόσοι που στην πραγματικότητα κάνουν την GridSearch χρονοβόρα και «μη βολική», ιδιαίτερα αν συμπεριλάβουμε σε αυτό και τον ήδη μεγάλο χρόνο εκτέλεσης του αλγορίθμου εκπαίδευσης του MLP ακόμα και για έναν συγκεκριμένο συνδυασμό παραμέτρων. 

Η διαδικασία που ακολουθήσαμε βασίστηκε στην εκτέλεση ελάχιστων μόνο συνδυασμών και στην προσπάθεια να αντιληφθούμε οι ίδιοι τάσεις στα δεδομένα, ώστε να προσεγγίσουμε ένα ικανοποιητικό μέγιστο με ταχύτητα μεγαλύτερη από αυτή της εξαντλητικής αναζήτησης. Για να το κάνουμε αυτό κάναμε αναζήτηση σε μεγάλα εύρη παραμέτρων και δεχθήκαμε πως οι βέλτιστες λύσεις θα βρίσκονται κάθε φορά κοντά σε αυτές που βρίσκαμε εμείς ως βέλτιστες με τις δεδομένες παραμέτρους που χρησιμποποιούσαμε κάθε φορά. Επίσης χωρίσαμε την αναζήτηση σε τρεις διακριτές αναζητήσεις, μία για κάθε solver.

Το συγκεκριμένο τμήμα της εργασίας είναι πιθανό να παρουσιάζεται αρκετά μπερδεμένο αλλά αυτό οφείλεται στους συγκεκριμένους τρεις παράγοντες:
•	Τρέχαμε ταυτόχρονα blocks κώδικα σε διαφορετικά Colab Notebooks, από διαφορετικούς λογαριασμούς η τοπικά σε διαφορετικούς υπολογιστές για να ξεπεράσουμε τους περιορισμούς του Colabως προς τη χρήση, καθώς και τους περιορισμούς των μηχανημάτων που είχαμε στη διάθεσή μας (τα οποία δυστυχώς αυτό τον καιρό ταλαιπωρούνται από πολλά demanding tasks).
•	Η διαδικασία δεν ήταν προκαθορισμένη και πολλές φορές λαμβάναμε την απόφαση για το επόμενο block που θα εκτελεστεί ανάλογα με την έκβαση του προηγούμενου.
Προσπαθήσαμε να συγκεντρώσουμε όλη τη δουλειά που κάναμε σε ένα Notebook και σας παρουσιάζουμε τη δουλειά μας παρακάτω.

Εύρεση βέλτιστου 'lbfgs' MLP ως προς f1-macro
"""

mlp_gs = MLPClassifier(solver = 'lbfgs')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(40,),(80,),(120,),(200,),(400,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [100,250,500,1000]
n_components = [25, 50, 90, 140, 200]
alpha = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__activation=activation,
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=2)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'lbfgs',activation='relu')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(300,),(400,),(500,)]
#activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant']
max_iter = [90,1000]
n_components = [120, 140, 160]
alpha = [5e-4,1e-3,5e-3]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'lbfgs')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(100,),(200,),(400,)]
activation = ['relu']
#h = [(40,),(80,),(120,),(200,),(400,)]
#activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [250,500,1000]
n_components = [25, 50, 90, 140]
alpha = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__activation = activation, 
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

h = [(300,),(400,),(500,)]
activation = ['relu']
#h = [(40,),(80,),(120,),(200,),(400,)]
#activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [400,500,600]
n_components = [70, 90, 110]
alpha = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__activation = activation, 
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

h = [(500,),(600,),(700,)]
activation = ['relu']
#h = [(40,),(80,),(120,),(200,),(400,)]
#activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant']
max_iter = [500]
n_components = [100, 110,120,140]
alpha = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__activation = activation, 
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Εύρεση βέλτιστου 'lbfgs' MLP ως προς F1-Micro"""

mlp_gs = MLPClassifier(solver = 'lbfgs')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(80,),(120,),(200,),(400,),(500,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [100,250,500,1000]
n_components = [25, 50, 90, 140, 200]
alpha = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__activation=activation,
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_micro', n_jobs=2)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'lbfgs',activation='relu')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(400,),(500,),(600,)]
#activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant']
max_iter = [80,100,150]
n_components = [120, 140, 160]
alpha = [5e-5,1e-4,5e-4]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter, mlp__alpha = alpha), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))

"""Παρακάτω παρουσιάζεται η διαδικασία για solver τύπου “adam” και διάφορυς συνδυασμούς υπερπαραμέτρων."""

mlp_gs = MLPClassifier(solver = 'adam')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(120,),(360,),(650,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [700,1000]
n_components = [ 40, 80,120]
alpha = [1e-5,1e-4]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter,mlp__activation = activation, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'adam')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(120,),(360,),(650,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [700,1000]
n_components = [ 40, 80,120]
alpha = [1e-5,1e-4]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter,mlp__activation = activation, mlp__alpha = alpha), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'adam')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(240,),(360,),(480,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant']
max_iter = [900,1000]
n_components = [ 36,40,44]
alpha = [1e-5,5e-5]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter,mlp__activation = activation, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'adam')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(550,),(650,),(750,)]
activation = ['relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant']
max_iter = [900,1000]
n_components = [ 35,40,44]
alpha = [5e-5,1e-4,5e-4]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter,mlp__activation = activation, mlp__alpha = alpha), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Παρακάτω παρουσιάζεται η διαδικασία εύρεσης βέλτιστων υπερπαραμέτρων για solver τύπου "sgd"."""

mlp_gs = MLPClassifier(solver = 'sgd')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(120,),(360,),(650,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [700,1000]
n_components = [ 40, 80,120]
alpha = [1e-5,1e-4]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter,mlp__activation = activation, mlp__alpha = alpha), cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

mlp_gs = MLPClassifier(solver = 'sgd')
selector = VarianceThreshold()
scaler = StandardScaler()
h = [(120,),(360,),(650,)]
activation = ['identity','logistic','tanh','relu']
#solver = ['lbfgs','sgd','adam']
learning_rate = ['constant','invscaling','adaptive']
max_iter = [700,1000]
n_components = [ 40, 80,120]
alpha = [1e-5,1e-4]
pipe = Pipeline(steps=[('selector',selector),('scaler',scaler),('pca', pca), ('mlp', mlp_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, mlp__hidden_layer_sizes=h,
                                    mlp__max_iter = max_iter,mlp__activation = activation, mlp__alpha = alpha), cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""## Γενικά συμπεράσματα για τη GridSearch στον MLP

Παρατηρούμε πως καταφέραμε να βελτιώσουμε σε έναν ικανοποιητικό βαθμό τον ταξινομητή MLP παρ’όλα αυτά οφείλουμε να αναφέρουμε πως δεν είμαστε βέβαιοι πως έχουμε πετύχει τα βέλτιστα αποτελέσματα για αυτόν τον ταξινομητή.  Και οι τρεις τύποι solver παρείχαν αποτελέσματα αρκετά κοντά μεταξύ τους και αφού η αναζήτησή μας δεν ήταν εξαντλητική μπορεί να αγνοήσαμε κάποιο συνδυασμό που να έκανε κάποιον από τους δύο solvers, “lbfgs” και “sgd”, να αποδίδουν καλύτερα από τον “adam”, ο οποίος στα πειράματά μας έδωσε τις δύο βέλτιστες λύσεις, ως προς f1-macro και f1-micro.

Τονίζουμε εδώ άλλη μια φορά πως το μεγάλο πλήθος υπερπαραμέτρων ως προς βελτιστοποίηση κατέστησε την εξαντλητική αναζήτηση μέσω GridSearch τρομερά χρονικά απαιτητική διαδικασία.

# SVM

Στο σημείο αυτό πρωτού παρουσιάσουμε τα συνολικά αποτελέσματα θα ελέγξουμε έναν τελευταίο τύπο ταξινομητή, τα δίκτυα SVM.

## Ορισμός απλού SVM ως benchmark

Στην ενότητα αυτή πρέπει να λάβουμε υπόψιν μας πως υπάρχουν δύο διαφορετικές υλοποιήσεις για τον SVM, η LinearSVC που υλοποιεί SVM με γραμμικό τύπο πυρήνα, και η SVC που έχει τη δυνατότητα τόσο για γραμμικούς όσο και για ‘rbf’ και ‘poly’ πυρήνες. Θα εξετάσουμε και τις δύο υλοποιήσεις. Παρακάτω θα ορίσουμε έναν απλό ταξινομητή από κάθε κατηγορία ως benchmark.
"""

from sklearn.svm import SVC 
from sklearn.svm import LinearSVC

svm_clf = SVC(class_weight='balanced', C = 1).fit(train, unbin_train_labels)
svm_preds = svm_clf.predict(test)

svm_acc = svm_clf.score(test, unbin_test_labels)

print(svm_acc)

svm_clf = LinearSVC(class_weight='balanced').fit(train, unbin_train_labels)
svm_preds = svm_clf.predict(test)
svm_acc = svm_clf.score(test, unbin_test_labels)
print(svm_acc)

"""## Εύρεση βέλτιστων υπερπαραμέτρων με GridSearch

Παρακάτω παρουσιάζεται η διαδικασία αναζήτησης βέλτιστων υπερπαραμέτρων και προεπεξεργασίας. Θα ερευνήσουμε ως προς τις παρακάτω παραμέτρους:

•	loss (linear)
•	tol
•	C
•	n_components (PCA)
•	gamma (non-linear)
•	degree (poly)

Σημειώνεται εδώ πως σπάσαμε τη GridSearch σε τμήματα, ανάλογα με τον τύπο πυρήνα και την υλοποίηση που χρησιμοποιήσαμε, ώστε να αποκλείσουμε γρηγορότερα τις υλοποιήσεις που δε δίνουν βέλτιστα αποτελέσματα και να εστιάσουμε την αναζήτηση στους συνδυασμούς με την καλύτερη επίδοση.

Αρχικά θα ελέγξουμε την υλοποίηση LinearSVC ως προς f1-macro.
"""

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = LinearSVC(class_weight='balanced')
n_components = [10, 25, 50, 90, 140, 200]
c = [0.25, 0.5, 1,5,10,50]
tol = [1e-5,1e-4,1e-3]
loss = ['hinge', 'squared_hinge']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__loss = loss),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [35, 50, 65]
c = [0.1,0.25, 0.5, ]
tol = [1e-5,1e-4]
loss = ['hinge', 'squared_hinge']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__loss = loss),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [45, 50,55]
c = [0.05, 0.1,0.2]
tol = [1e-5,1e-4]
loss = ['hinge', 'squared_hinge']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__loss = loss),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [40, 45]
c = [0.01, 0.05, 0.1]
tol = [1e-5,1e-4]
loss = ['hinge', 'squared_hinge']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__loss = loss),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Ο παραπάνω αποτελεί το βέλτιστο LinearSVC() ταξινομητή ως προς f1-macro. 
Θα ακολουθήσουμε την ίδια διαδικασία και για f1-micro. Ήδη υποψιαζόμαστε πως η υλοποίηση της LinearSVC υστερεί της SVC στο συγκεκριμένο dataset, όπως παρατηρήσαμε από τα πρώτα κιόλας benchmarks.
"""

n_components = [10, 25, 50, 90, 140]
c = [0.25, 0.5, 1,5,10]
tol = [1e-5,1e-4]
loss = ['hinge', 'squared_hinge']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__loss = loss),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [40, 45]
c = [0.01, 0.05, 0.1]
tol = [1e-5,1e-4]
loss = ['hinge', 'squared_hinge']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__loss = loss),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Παρατηρούμε, όπως είχαμε προβλέψει και από πριν πως δεν οδηγούμαστε σε ικανοποιητικά αποτελέσματα. Θα ελέγξουμε τώρα την υλοποίηση της SVC με kernel = 'linear'"""

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(kernel='linear', class_weight='balanced')
n_components = [25, 50, 90]
c = [0.25, 0.5, 1,5,10]
tol = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Ήδη παρατηρούμε πως από την πρώτη κιόλας GridSearch βρήκαμε καλύτερα αποτελέσματα."""

n_components = [70,90,110]
c = [0.05,0.1,0.25, 0.5]
tol = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(55,80,5)
c = [0.15,0.25,0.35]
tol = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Παρατηρούμε πως πετύχαμε ικανοποιητική αύξηση στο f1-macro αλλάζοντας από την υλοποίηση της LinearSVC() σε αυτή της SVC με linear kernel.

Θα εξετάσουμε τώρα και για f1-micro με την ίδια υλοποίηση.
"""

n_components = [25, 50, 90]
c = [0.25, 0.5, 1,5,10]
tol = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(35,60,5)
c = [0.75, 1,1.5]
tol = [1e-5,1e-4,1e-3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Θεωρούμε, λοιπόν πως βρήκαμε και τη βέλτιστη υλοποίηση για f1-micro.

Θα ελέγξουμε τώρα την υλοποίηση της SVC με πυρήνα 'rbf'.
"""

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='rbf' )
n_components = [ 25, 50, 90]
c = [0.25, 0.5, 1,5,10]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='rbf' )
n_components = range(35,70,5)
c = [ 2.5,5,7.5]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = [40]
c = [ 1.5,2.5,3.5]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Θεωρούμε πάλι πως βρήκαμε τη βέλτιστη υλοποίηση SVC με πυρήνα rbf και θα κάνουμε το ίδιο για f1-micro"""

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='rbf' )
n_components = [ 25, 50, 90]
c = [0.25, 0.5, 1,5,10]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(35,70,5)
c = [ 0.8, 1,1.5,2]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(37,45,2)
c = [ 1.8,2,2.2,2.4]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale']
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Πρόκειται να ελέγξουμε την τελευταία δυνατή υλοποίηση του SVC, δηλαδή με πυρήνες 'poly'."""

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [10, 25, 50, 90, 140, 200]
c = [0.25, 0.5, 1,5,10,50]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
degree = [2,3,4,5]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [10, 25, 50, 90, 140, 200]
c = [0.25, 0.5, 1,5,10,50]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
degree = [3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [10, 25, 50, 90, 140, 200]
c = [0.25, 0.5, 1,5,10,50]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
degree = [4]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = range(35,50,5)
c = [ 1,2,3]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale']
degree = [3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

n_components = range(35,55,5)
c = [7.5,10,15]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale']
degree = [4]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_macro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""Θα αναζητήσουμε τώρα τη βέλτιστη λύση για f1-micro.

"""

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [10, 25, 50, 90, 140, 200]
c = [0.25, 0.5, 1,5,10,50]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
degree = [2,3,4,5]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_mιcro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [10, 25, 50, 90, 140, 200]
c = [0.25, 0.5, 1,5,10,50]
tol = [1e-5,1e-4,1e-3]
gamma = ['scale', 'auto']
degree = [2,3,4,5]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [40,45, 50,55,60]
c = [0.15,0.25, 0.35]
tol = [1e-5,5e-5,1e-6]
gamma = ['auto']
degree = [3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

selector = VarianceThreshold()
scaler = StandardScaler()
svm_gs = SVC(class_weight='balanced', kernel='poly' )
n_components = [58,60,65,70]
c = [0.1,0.15,0.2]
tol = [1e-5]
gamma = ['auto']
degree = [3]
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler),('pca', pca), ('svc', svm_gs)])
estimator = GridSearchCV(pipe, dict(pca__n_components=n_components,  svc__C = c, svc__tol = tol, svc__gamma=gamma,svc__degree = degree),
                         cv=5, scoring='f1_micro', n_jobs=-1)
start_time = time.time()
estimator.fit(train, unbin_train_labels)
preds = estimator.predict(test)
print("Συνολικός χρόνος fit και predict: %s seconds" % (time.time() - start_time))
print(classification_report(unbin_test_labels, preds))
print(estimator.best_estimator_)
print(estimator.best_params_)

"""## Γενικά συμπεράσματα για την GridSearch στον SVM

Ένα από τα πρώτα ξεκάθαρα συμπεράσμα που σχηματίζουμε είναι πως η υλοποίηση της LinearSVC υστερεί κατά πολύ της SVC ως προς τα αποτελέσματα που μπορεί να πετύχει. Παρατηρούμε πως τα βέλτιστα αποτελέσματα συναντώνται για τύπο πυρήνα “rbf” με διαφορετικές μάλιστα υπερπαραμέτρους για την f1-macro και την f1-micro. Γενικά θεωρούμε πως καταφέραμε με την GridSearch να ερευνήσουμε ένα ικανοποιητικό ποσοστό των συνδυασμών για τη συγκεκριμένη υλοποίηση πράγμα που μας επιτρέπει να είμαστε αρκετά βέβαιοι πως τα αποτελέσματα που βρήκαμε προσεγγίζουν ικανοποιητικά τις βέλτιστες λύσεις.

# Συγκεντρωτική Παρουσίαση Αποτελεσμάτων

Στο σημείο αυτό θα γίνει παρουσίαση των βέλτιστων ταξινομητών κάθε είδους και κάθε μετρικής, σύγκριση με τους απλούς ταξινομητές που είχαμε ως benchmarks αλλά και μεταξύ τους και τέλος σχολιασμός των αποτελεσμάτων τους.

## Dummy Classifier
"""

dc_stratified = DummyClassifier(strategy="stratified")
model = dc_stratified.fit(train, unbin_train_labels)
preds = dc_stratified.predict(test)
dummy_accuracy = dc_stratified.score(test, unbin_test_labels) 
print(dummy_accuracy)

dm_bench = DummyClassifier(strategy="stratified")
start_time = time.time()
dm_bench.fit(train,unbin_train_labels)
dm_bench_preds = dm_bench.predict(test)
end_time = time.time()
dm_bench_accuracy = dm_bench.score(test, unbin_test_labels) 
dm_bench_f1_micro = f1_score(unbin_test_labels, dm_bench_preds, average='micro')
dm_bench_f1_macro = f1_score(unbin_test_labels, dm_bench_preds, average='macro')
dm_bench_cm = confusion_matrix(unbin_test_labels, dm_bench_preds)
dm_bench_total_time = end_time - start_time
print("Συνολικός χρόνος fit και predict: %s seconds" % (dm_bench_total_time))
print(classification_report(unbin_test_labels,dm_bench_preds))
sns.heatmap(dm_bench_cm.T, square=True, annot=True, fmt='d', cbar=False)

"""## Gaussian Naive Bayes

Benchmark Gaussian Naive Bayes
"""

gnb_bench = GaussianNB()
start_time = time.time()
gnb_bench.fit(train,unbin_train_labels)
gnb_bench_preds = gnb_bench.predict(test)
end_time = time.time()
gnb_bench_accuracy = gnb_bench.score(test, unbin_test_labels) 
gnb_bench_f1_micro = f1_score(unbin_test_labels, gnb_bench_preds, average='micro')
gnb_bench_f1_macro = f1_score(unbin_test_labels, gnb_bench_preds, average='macro')
gnb_bench_cm = confusion_matrix(unbin_test_labels, gnb_bench_preds)
gnb_bench_total_time = end_time - start_time
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,gnb_bench_preds))
sns.heatmap(gnb_bench_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Συγκεκριμένα στο ψηφίο «1» το precision είναι 0.48 που σημαίνει πως πάνω από 1 στα 2 δείγματα που ο ταξινομητής ταξινομεί στην κλάση «1» ανήκουν πραγματικά σε μια άλλη κλάση. Κάτι ανάλογο συναντάται και στο ψηφίο «6», το οποίο έχει precision 0.58. 

Αντίστοιχα, τα ψηφία «2», «4» και «9» έχουν μικρό recall, το οποίο σημαίνει πως ο ταξινομητής αποτυγχάνει να κατατάξει σωστά πολλά από τα δείγματα που ανήκουν σε αυτές τις κατηγορίες.

**F1-macro and F1-Micro Optimized Gaussian Naive Bayes**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 70
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=70)
gnb = GaussianNB()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('GNB', gnb)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
gnb_macro_opt_preds = pipe.predict(test)
end_time = time.time()
gnb_macro_opt_accuracy = pipe.score(test, unbin_test_labels) 
gnb_macro_opt_f1_micro = f1_score(unbin_test_labels, gnb_macro_opt_preds, average='micro')
gnb_macro_opt_f1_macro = f1_score(unbin_test_labels, gnb_macro_opt_preds, average='macro')
gnb_macro_opt_cm = confusion_matrix(unbin_test_labels, gnb_macro_opt_preds)
gnb_macro_opt_total_time = end_time - start_time
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,gnb_macro_opt_preds))
sns.heatmap(gnb_macro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Η βελτίωση μετά την προεπεξεργασία και την εύρεση βέλτιστων παραμέτρων είναι τρομερά αισθητή σε αυτόν τον ταξινομητή. 

Παύουμε πλέον να συναντάμε χαμηλά ποσοστά στο recall αφού όλα ξεπερνούν το 0.78 και το precision έχει ανέβει και αυτό αισθητά. Συγκεκριμένα τα δύο πιο «επικίνδυνα» ψηφία είναι το «8» και το «9» τα οποία έχουν το χαμηλότερο πλέον precision, 0.75 και 0.64 αντίστοιχα, και συνεπώς και τα χαμηλότερα f1-scores, 0.82 και 0.71 αντίστοιχα.

Η άσχημη επίδοση στο "9" παρά το μεγάλο ποσοστό δειγμάτων του που υπήρχαν στο train dataset πιθανώς να οφείλεται στις πολλές ομοιότητες του ψηφίου με άλλα ψηφία που πιθανώς δημιουργούν σύγχυση, όπως τα «3», «5» και «8».

## KNN

Benchmark KNN
"""

knn_bench = KNeighborsClassifier()
start_time = time.time()
knn_bench.fit(train,unbin_train_labels)
knn_bench_preds = knn_bench.predict(test)
end_time = time.time()
knn_bench_accuracy = knn_bench.score(test, unbin_test_labels) 
knn_bench_f1_micro = f1_score(unbin_test_labels, knn_bench_preds, average='micro')
knn_bench_f1_macro = f1_score(unbin_test_labels, knn_bench_preds, average='macro')
knn_bench_cm = confusion_matrix(unbin_test_labels, knn_bench_preds)
knn_bench_total_time = end_time - start_time
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,knn_bench_preds))
sns.heatmap(knn_bench_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Παρόμοια όπως και στον GNB ταξινομητή, αλλά με πολύ υψηλότερα ποσοστά ως βάση και στον ΚΝΝ συναντάμε μεγάλο πρόβλημα με το recall του ψηφίου «9», το οποίο είναι 0.62.

**F1-Macro Optimized KNN**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 70
* KNN: n_neighbors = 5 , metric = 'euclidean', weights = 'distance'
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=36)
knn = KNeighborsClassifier(n_neighbors=5,metric='euclidean',weights='distance')
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('KNN', knn)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
knn_macro_opt_preds = pipe.predict(test)
end_time = time.time()
knn_macro_opt_accuracy = pipe.score(test, unbin_test_labels) 
knn_macro_opt_f1_micro = f1_score(unbin_test_labels, knn_macro_opt_preds, average='micro')
knn_macro_opt_f1_macro = f1_score(unbin_test_labels, knn_macro_opt_preds, average='macro')
knn_macro_opt_cm = confusion_matrix(unbin_test_labels, knn_macro_opt_preds)
knn_macro_opt_total_time = end_time - start_time
print(knn_macro_opt_f1_macro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,knn_macro_opt_preds))
sns.heatmap(knn_macro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Η διαδικασία του optimization βελτιώνει συνολικά τα αποτελέσματα και συγκεκριμένα το recall του rate κατά 0.11 από 0.62 σε 0.73.

**KNN F1-Micro Optimized**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 38
* KNN: n_neighbors = 4 , metric = 'euclidean', weights = 'distance'
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=38)
knn = KNeighborsClassifier(n_neighbors=4,metric='euclidean',weights='distance')
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('KNN', knn)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
knn_micro_opt_preds = pipe.predict(test)
end_time = time.time()
knn_micro_opt_accuracy = pipe.score(test, unbin_test_labels) 
knn_micro_opt_f1_micro = f1_score(unbin_test_labels, knn_micro_opt_preds, average='micro')
knn_micro_opt_f1_macro = f1_score(unbin_test_labels, knn_micro_opt_preds, average='macro')
knn_micro_opt_cm = confusion_matrix(unbin_test_labels, knn_micro_opt_preds)
knn_micro_opt_total_time = end_time - start_time
print(knn_micro_opt_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,knn_micro_opt_preds))
sns.heatmap(knn_micro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Και στην περίπτωση του optimization ως προς F1-micro παρατηρείται η ίδια βελτίωση στο recall του ψηφίου «9» και πολύ μικρές βελτιώσεις σε όλα τα υπόλοιπα metrics συγκριτικά με το f1-macro optimization του KNN.

## SVM

### LinearSVC

Benchmark LinearSVC
"""

svc_lin_bench = LinearSVC()
start_time = time.time()
svc_lin_bench.fit(train,unbin_train_labels)
svc_lin_bench_preds = svc_lin_bench.predict(test)
end_time = time.time()
svc_lin_bench_accuracy = svc_lin_bench.score(test, unbin_test_labels) 
svc_lin_bench_f1_micro = f1_score(unbin_test_labels, svc_lin_bench_preds, average='micro')
svc_lin_bench_f1_macro = f1_score(unbin_test_labels, svc_lin_bench_preds, average='macro')
svc_lin_bench_cm = confusion_matrix(unbin_test_labels, svc_lin_bench_preds)
svc_lin_bench_total_time = end_time - start_time
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,svc_lin_bench_preds))
sns.heatmap(svc_lin_bench_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Ο LinearSVC φαίνεται να ανταποκρίνεται διαφορετικά σε δύο κατηγορίες ψηφίων. Στα ψηφία «8», «9» και «7» τα οποία αναφέρονται με αύξουσα σειρά f1-score έχει απόδοση από 0.7 έως 0.8. Αντίθετα στα υπόλοιπα ψηφία το f1-score ξεπερνά το 0.86.

**F1-Macro Optimized LinearSVC**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 70
* LinearSVC: C=0.05 , loss='squared_hinge',tol=0.0001
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=45)
svc = LinearSVC(class_weight='balanced', C=0.05, loss='squared_hinge',tol=0.0001)
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVC', svc)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
svc_lin_macro_opt_preds = pipe.predict(test)
end_time = time.time()
svc_lin_macro_opt_accuracy = pipe.score(test, unbin_test_labels) 
svc_lin_macro_opt_f1_micro = f1_score(unbin_test_labels, svc_lin_macro_opt_preds, average='micro')
svc_lin_macro_opt_f1_macro = f1_score(unbin_test_labels, svc_lin_macro_opt_preds, average='macro')
svc_lin_macro_opt_cm = confusion_matrix(unbin_test_labels, svc_lin_macro_opt_preds)
svc_lin_macro_opt_total_time = end_time - start_time
print(svc_lin_macro_opt_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,svc_lin_macro_opt_preds))
sns.heatmap(svc_lin_macro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Μετά την βελτιστοποίηση των υπερπαραμέτρων ως προς f1-macro «προβληματικά» παραμένουν τα ψηφία «7» και «9» με 0.83 και 0.85 f1-score, το οποίο είναι αισθητά αυξημένο συγκριτικά με πριν. Το κατώφλι του f1-score για τα «καλά» ψηφία είναι πλέον 0.9 στο f1-score, ενώ το ψηφίο «8» έχει πάψει πλέον να συγκαταλέγεται στα προβληματικά.

**F1-Micro Optimized LinearSVC**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 45
* LinearSVC: C=0.1 , loss='hinge',tol=1e-5
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=45)
svc = LinearSVC(class_weight='balanced', C=0.1, loss='hinge',tol=1e-5)
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVC', svc)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
svc_lin_micro_opt_preds = pipe.predict(test)
end_time = time.time()
svc_lin_micro_opt_accuracy = pipe.score(test, unbin_test_labels) 
svc_lin_micro_opt_f1_micro = f1_score(unbin_test_labels, svc_lin_micro_opt_preds, average='micro')
svc_lin_micro_opt_f1_macro = f1_score(unbin_test_labels, svc_lin_micro_opt_preds, average='macro')
svc_lin_micro_opt_cm = confusion_matrix(unbin_test_labels, svc_lin_micro_opt_preds)
svc_lin_micro_opt_total_time = end_time - start_time
print(svc_lin_micro_opt_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,svc_lin_micro_opt_preds))
sns.heatmap(svc_lin_micro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""H βελτιστοποίηση ως προς f1-micro δε λειτουργεί πολύ αποτελεσματικά σε αυτή την περίπτωση, καθώς αν και τα συνολικά ποσοστά αυξήθηκαν δεν βελτιώθηκαν τόσο όσο κατά την f1-macro και το ψηφίο «8» εξακολουθεί να συγκαταλέγεται μαζί με τα «7» και «9» στα προβληματικά.

### SVC
"""

svc_bench = SVC()
start_time = time.time()
svc_bench.fit(train,unbin_train_labels)
svc_bench_preds = svc_bench.predict(test)
end_time = time.time()
svc_bench_accuracy = svc_bench.score(test, unbin_test_labels) 
svc_bench_f1_micro = f1_score(unbin_test_labels, svc_bench_preds, average='micro')
svc_bench_f1_macro = f1_score(unbin_test_labels, svc_bench_preds, average='macro')
svc_bench_cm = confusion_matrix(unbin_test_labels, svc_bench_preds)
svc_bench_total_time = end_time - start_time
print(svc_bench_f1_macro)
print(svc_bench_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,svc_bench_preds))
sns.heatmap(svc_bench_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Η υλοποίηση SVC φαίνεται εξαρχής να πετυχαίνει πολύ καλά αποτελέσματα με f1-macro και f1-micro score που φτάνει το 0.955. Και εδώ παρατηρούμε πως το προβληματικό ψηφίο είναι το «9» αλλά έχουμε φτάσει πλέον σε σημείο που οι διαφορές είναι ελάχιστες και τα χαμηλότερα ποσοστά εξαιρετικά υψηλά.

**F1-Macro Optimized SVC**


* VarianceThreshold
* StandardScaler
* PCA: n_components = 40
* SVC: kernel='rbf',class_weight='balanced', C=1.5,tol=1e-5,gamma='scale'
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=40)
svc = SVC(kernel='rbf',class_weight='balanced', C=1.5,tol=1e-5,gamma='scale')
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVC', svc)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
svc_macro_opt_preds = pipe.predict(test)
end_time = time.time()
svc_macro_opt_accuracy = pipe.score(test, unbin_test_labels) 
svc_macro_opt_f1_micro = f1_score(unbin_test_labels, svc_macro_opt_preds, average='micro')
svc_macro_opt_f1_macro = f1_score(unbin_test_labels, svc_macro_opt_preds, average='macro')
svc_macro_opt_cm = confusion_matrix(unbin_test_labels, svc_macro_opt_preds)
svc_macro_opt_time = end_time - start_time
print(svc_macro_opt_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,svc_macro_opt_preds))
sns.heatmap(svc_macro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""**F1-Micro Optimized SVC**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 39
* SVC: kernel='rbf',class_weight='balanced', C=2.2 ,tol=1e-4, gamma='scale'
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=39)
svc = SVC(kernel='rbf',class_weight='balanced', C=2.2,tol=0.001,gamma='scale')
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVC', svc)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
svc_micro_opt_preds = pipe.predict(test)
end_time = time.time()
svc_micro_opt_accuracy = pipe.score(test, unbin_test_labels) 
svc_micro_opt_f1_micro = f1_score(unbin_test_labels, svc_micro_opt_preds, average='micro')
svc_micro_opt_f1_macro = f1_score(unbin_test_labels, svc_micro_opt_preds, average='macro')
svc_micro_opt_cm = confusion_matrix(unbin_test_labels, svc_micro_opt_preds)
svc_micro_opt_time = end_time - start_time
print(svc_micro_opt_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,svc_micro_opt_preds))
sns.heatmap(svc_micro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Και για τα δύο optimizations του SVC αναφέρουμε πως οι βελτιώσεις είναι ελάχιστες, της τάξης του 0.005, πράγμα λογικό αν σκεφτεί κανείς την εξαιρετική απόδοση που έχει αρχικά ο ταξινομητής. Ανάμεσα στα δύο optimizations, αυτό ως προς f1-macro βελτιώνει περισσότερο το f1-score του ψηφίου «9».

## MLP

**MLP Benchmark**
"""

mlp_bench = MLPClassifier()
start_time = time.time()
mlp_bench.fit(train,unbin_train_labels)
mlp_bench_preds = mlp_bench.predict(test)
end_time = time.time()
mlp_bench_accuracy = mlp_bench.score(test, unbin_test_labels) 
mlp_bench_f1_micro = f1_score(unbin_test_labels, mlp_bench_preds, average='micro')
mlp_bench_f1_macro = f1_score(unbin_test_labels, mlp_bench_preds, average='macro')
mlp_bench_cm = confusion_matrix(unbin_test_labels, mlp_bench_preds)
mlp_bench_time = end_time - start_time
print(mlp_bench_f1_macro)
print(mlp_bench_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,mlp_bench_preds))
sns.heatmap(mlp_bench_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Ο βασικός MLP αποδίδει και αυτός καλά συναντώντας πρόβλημα κυρίως στο ψηφίο «7» με f1-score 0.83.

**MLP F1-Macro Optimized**


* VarianceThreshold
* StandardScaler
* PCA: n_components = 40
* MLP: activation='relu',solver='adam',alpha=1e-5,hidden_layer_sizes=(480,),max_iter=900
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=40)
mlp = MLPClassifier(activation='relu',solver='adam',alpha=1e-5,hidden_layer_sizes=(480,),max_iter=900)
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('MLP', mlp)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
mlp_macro_opt_preds = pipe.predict(test)
end_time = time.time()
mlp_macro_opt_accuracy = pipe.score(test, unbin_test_labels) 
mlp_macro_opt_f1_micro = f1_score(unbin_test_labels, mlp_macro_opt_preds, average='micro')
mlp_macro_opt_f1_macro = f1_score(unbin_test_labels, mlp_macro_opt_preds, average='macro')
mlp_macro_opt_cm = confusion_matrix(unbin_test_labels, mlp_macro_opt_preds)
mlp_macro_opt_time = end_time - start_time
print(mlp_macro_opt_f1_macro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,mlp_macro_opt_preds))
sns.heatmap(mlp_macro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""**F1-Micro Optimized MLP**

* VarianceThreshold
* StandardScaler
* PCA: n_components = 44
* MLP: activation='relu',solver='adam',alpha=1e-4,hidden_layer_sizes=(650,),max_iter=1000
"""

selector = VarianceThreshold()
scaler = StandardScaler()
pca = PCA(n_components=44)
mlp = MLPClassifier(activation='relu',solver='adam',alpha=1e-4,hidden_layer_sizes=(650,),max_iter=1000)
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('MLP', mlp)])
start_time = time.time()
pipe.fit(train,unbin_train_labels)
mlp_micro_opt_preds = pipe.predict(test)
end_time = time.time()
mlp_micro_opt_accuracy = pipe.score(test, unbin_test_labels) 
mlp_micro_opt_f1_micro = f1_score(unbin_test_labels, mlp_micro_opt_preds, average='micro')
mlp_micro_opt_f1_macro = f1_score(unbin_test_labels, mlp_micro_opt_preds, average='macro')
mlp_micro_opt_cm = confusion_matrix(unbin_test_labels, mlp_micro_opt_preds)
mlp_micro_opt_time = end_time - start_time
print(mlp_micro_opt_f1_micro)
print("Συνολικός χρόνος fit και predict: %s seconds" % (end_time - start_time))
print(classification_report(unbin_test_labels,mlp_micro_opt_preds))
sns.heatmap(mlp_micro_opt_cm.T, square=True, annot=True, fmt='d', cbar=False);

"""Και τα δύο optimizations λειτουργούν πολύ καλά, με το f1-macro ιδιαίτερα να βελτιώνει τρομερά το f1-score του ψηφίου "7". Αξιοσημείωτο είναι το γεγονός πως το f1-score του ψηφίου «9» μειώθηκε και στα δύο optimizations.

## Γενική παρατήρηση σχετικά με τις υπερπαραμέτρους

Σε αυτό το σημείο θα θέλαμε να αναφέρουμε αν και πιθανώς να έχει γίνει ήδη εμφανές από τα παραπάνω πως οι βέλτιστοι συνδυασμοί υπερπαραμέτρων για optimizations ως προς f1-micro και f1-macro μπορεί να διαφέρουν **πολύ** μεταξύ τους.

## F1 Comparison Bar Plots
"""

x_labels = ['Dummy','GNB','KNN','LinearSVC','SVC','MLP']
y_labels_macro = [dm_bench_f1_macro,gnb_macro_opt_f1_macro,knn_macro_opt_f1_macro,svc_lin_macro_opt_f1_macro,svc_macro_opt_f1_macro,mlp_macro_opt_f1_macro]
y_labels_micro = [dm_bench_f1_micro ,gnb_macro_opt_f1_micro,knn_micro_opt_f1_micro,svc_lin_micro_opt_f1_micro,svc_micro_opt_f1_micro,mlp_micro_opt_f1_micro]

print('\033[1m' + "Χρόνοι εκτέλεσης: " + '\033[0m', '\n')
print("GNB:")
print("     'f1_micro': ", gnb_macro_opt_total_time, "sec")
print("     'f1_macro': ", gnb_macro_opt_total_time, 'sec\n')

print("kNN:")
print("     'f1_micro': ", knn_micro_opt_total_time, "sec")
print("     'f1_macro': ", knn_macro_opt_total_time, 'sec\n')

print("MLP:")
print("     'f1_micro': ", mlp_micro_opt_time, "sec")
print("     'f1_macro': ", mlp_macro_opt_time, 'sec\n')

print("LinearSVC:")
print("     'f1_micro': ", svc_lin_micro_opt_total_time, "sec")
print("     'f1_macro': ", svc_lin_macro_opt_total_time, 'sec\n')

print("SVC:")
print("     'f1_micro': ", svc_micro_opt_time, "sec")
print("     'f1_macro': ", svc_macro_opt_time, 'sec\n\n\n')

"""Παρατηρούμε όπως αναφέραμε και νωρίτερα πως οι ταξινομητές **GΝΒ και KNN** απαιτούν σχεδόν 0.1 sec και για το λόγο αυτό είναι και δυνατή η εξαντλητική αναζήτηση με τη GridSearch, αφού και οι παράμετροι προς βελτιστοποίηση είναι λίγες.

Οι **LinearSVC και SVC** απαιτούν περίπου το διπλάσιο χρόνο, σε συγκεκριμένες περιπτώσεις πυρήνα και αρκετά παραπάνω. Αυτό σε συνδυασμό με το μεγαλύτερο αριθμό παραμέτρων που έχουν προς βελτιστοποίηση καθιστά τη διαδικασία αναζήτησης με GridSearch εφικτή μεν αλλά απαιτητική δε.

Τέλος, ο **MLP** απαιτεί περίπου 3 sec ή αλλιώς 30 περίπου φορές το χρόνο των πιο γρήγορων ταξινομητών. Αν λάβει κανείς υπόψιν του το μεγάλο αριθμ’ο υπερπαραμέτρων προς βελτίωση καταλαβαίνει πως η εξαντλητική αναζήτηση με GridSearch είναι μια διαδικασία χρονοβόρα και υπολογιστικά απαιτητική που καλό είναι να αποφύγει. Αντίθετα με αναζητήσεις σε πιο αραιά διαστήματα και ακολουθώντας τις τάσεις στις παραμέτρους είναι δυνατό να βρεθούν αρκετά ικανοποιητικά αποτελέσματα.


"""

print('\033[1m' + "Μεταβολή επίδοσης: " + '\033[0m','\n')
print("gnb:")
print("     F1-Micro πριν τη βελτιστοποίηση: ", round(gnb_bench_f1_micro*100,1),"%")
print("     F1-Macro πριν τη βελτιστοποίηση: ", round(gnb_bench_f1_macro*100,1),"%")
print("     F1-Micro μετά τη βελτιστοποίηση με 'f1_micro': ", round(gnb_macro_opt_f1_micro*100,1),"%")
print("     F1-Macro μετά τη βελτιστοποίηση με 'f1_macro': ", round(gnb_macro_opt_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((gnb_macro_opt_f1_micro-gnb_bench_f1_micro)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((gnb_macro_opt_f1_macro-gnb_bench_f1_macro)*100,1),"%\n")

print("ΚΝΝ:")
print("     F1-Micro πριν τη βελτιστοποίηση: ", round(knn_bench_f1_micro*100,1),"%")
print("     F1-Macro πριν τη βελτιστοποίηση: ", round(knn_bench_f1_macro*100,1),"%")
print("     F1-Micro μετά τη βελτιστοποίηση με 'f1_micro': ", round(knn_micro_opt_f1_micro*100,1),"%")
print("     F1-Macro μετά τη βελτιστοποίηση με 'f1_macro': ", round(knn_macro_opt_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((knn_micro_opt_f1_micro-knn_bench_f1_micro)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((knn_macro_opt_f1_macro-knn_bench_f1_macro)*100,1),"%\n")


print("MLP:")
print("     F1-Micro πριν τη βελτιστοποίηση: ", round(mlp_bench_f1_micro*100,1),"%")
print("     F1-Macro πριν τη βελτιστοποίηση: ", round(mlp_bench_f1_macro*100,1),"%")
print("     F1-Micro μετά τη βελτιστοποίηση με 'f1_micro': ", round(mlp_micro_opt_f1_micro*100,1),"%")
print("     F1-Macro μετά τη βελτιστοποίηση με 'f1_macro': ", round(mlp_macro_opt_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((mlp_micro_opt_f1_micro-mlp_bench_f1_micro)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((mlp_macro_opt_f1_macro-mlp_bench_f1_macro)*100,1),"%\n")

print("LinearSVC:")
print("     F1-Micro πριν τη βελτιστοποίηση: ", round(svc_lin_bench_f1_micro*100,1),"%")
print("     F1-Macro πριν τη βελτιστοποίηση: ", round(svc_lin_bench_f1_macro*100,1),"%")
print("     F1-Micro μετά τη βελτιστοποίηση με 'f1_micro': ", round(svc_lin_micro_opt_f1_micro*100,1),"%")
print("     F1-Macro μετά τη βελτιστοποίηση με 'f1_macro': ", round(svc_lin_macro_opt_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((svc_lin_micro_opt_f1_micro-svc_lin_bench_f1_micro)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((svc_lin_macro_opt_f1_macro-svc_lin_bench_f1_macro)*100,1),"%\n")

print("SVC:")
print("     F1-Micro πριν τη βελτιστοποίηση: ", round(svc_bench_f1_micro*100,1),"%")
print("     F1-Macro πριν τη βελτιστοποίηση: ", round(svc_bench_f1_macro*100,1),"%")
print("     F1-Micro μετά τη βελτιστοποίηση με 'f1_micro': ", round(svc_micro_opt_f1_micro*100,1),"%")
print("     F1-Macro μετά τη βελτιστοποίηση με 'f1_macro': ", round(svc_macro_opt_f1_macro*100,1),'%\n')
print("     Βελτίωση με χρήση της 'f1_micro': ", round((svc_micro_opt_f1_micro-svc_bench_f1_micro)*100,1),"%")
print("     Βελτίωση με χρήση της 'f1_macro': ", round((svc_macro_opt_f1_macro-svc_bench_f1_macro)*100,1),"%\n")

"""Παραπάνω παρατηρούμε τα εξής:

* Ο **SVC**, ο οποίος είναι και ο καλύτερος ταξινομητής και ως προς τις 2 (f1-micro,f1-macro)  μετρικές καταφέρνει χωρίς καμία προεπεξεργασία και παραμετροποίηση να ανταπεξέλθει εξαιρετικά στα δεδομένα. Η προεπεξεργασία και η παραμετροποίηση βελτιώνουν μεν τον ταξινομητή, προκαλούν δε ελάχιστες διαφορές.

*	Οι **KNN και MLP** έχουν αρκετά καλά αρχικά αποτελέσματα αλλά η εισαγωγή προεπεξεργασίας και παραμετροποίησης τους βελτιώνει αισθητά κατά περίπου 3% στις μετρικές που εξετάζουμε.
*	Ο **Linear SVC** μπορεί να μην φτάνει ακριβώς στα ίδια επίπεδα με τους προηγούμενους ταξινομητές αλλά η προεπξεργασία και η παραμετροποίηση φαίνεται να τον βοηθά πολύ, καθώς πετυχαίνουμε αρκετά μεγάλες αυξήσεις και στις δύο μετρικές.
*	Τέλος, ο **GNB** βελτιώνεται τρομερά με τη μείωση της διαστατικότητας, πράγμα που δείχνει πως η μέθοδος αυτή μπορεί να αποδώσει καλύτερα όταν υπάρχουν λιγότερα χαρακτηριστικά με μεγαλύτερη σημασία.

"""

print('\033[1m' + "Σύγκριση ταξινομητών ανά μετρική: " + '\033[0m','\n')
data = {'dummy': [dm_bench_f1_micro, dm_bench_f1_macro],
        'gnb': [gnb_macro_opt_f1_micro, gnb_macro_opt_f1_macro],
        'kNN': [knn_micro_opt_f1_micro,knn_macro_opt_f1_macro],
        'MLP': [mlp_micro_opt_f1_micro,mlp_macro_opt_f1_macro],
        'LinearSVC': [svc_lin_micro_opt_f1_micro, svc_lin_macro_opt_f1_macro],
        'SVC': [svc_micro_opt_f1_micro, svc_macro_opt_f1_macro],
        'metric': ['f1_micro','f1_macro']}
dataframe = pd.DataFrame(data, columns = ['dummy','gnb','kNN','MLP','LinearSVC','SVC','metric'])
df = pd.melt(dataframe, id_vars="metric", var_name="Classifier", value_name="score")
fig_dims = (16, 6)
fig, ax = plt.subplots(figsize=fig_dims)
sns.barplot(x='metric', y='score', hue='Classifier', data=df);

